{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102fedde-12f9-469d-9714-62df4bd9120f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:09:23.958723Z",
     "iopub.status.busy": "2024-04-14T07:09:23.958322Z",
     "iopub.status.idle": "2024-04-14T07:09:23.968781Z",
     "shell.execute_reply": "2024-04-14T07:09:23.968207Z",
     "shell.execute_reply.started": "2024-04-14T07:09:23.958704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.data import (\n",
    "    get_data_period,\n",
    "    read_data,\n",
    "    print_info,\n",
    "    print_info_targets,\n",
    "    prepare_dataset,\n",
    "    read_data\n",
    ")\n",
    "from ptls.data_load.datasets import PersistDataset\n",
    "from catboost import CatBoostClassifier\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.data_load.utils import FeatureDict\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as ptl\n",
    "\n",
    "from ptls.nn import TrxEncoder, TransformerSeqEncoder, Head, RnnSeqEncoder\n",
    "from tqdm.auto import tqdm \n",
    "import polars as pl\n",
    "\n",
    "from functools import partial\n",
    "from ptls.frames.supervised import SeqToTargetDataset, SequenceToTarget\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from functools import partial\n",
    "\n",
    "from ptls.data_load.datasets import inference_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80854699-6c14-40a4-b540-d40b9afe2242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T23:48:11.241982Z",
     "iopub.status.busy": "2024-04-13T23:48:11.241308Z",
     "iopub.status.idle": "2024-04-13T23:48:11.253588Z",
     "shell.execute_reply": "2024-04-13T23:48:11.252974Z",
     "shell.execute_reply.started": "2024-04-13T23:48:11.241953Z"
    },
    "tags": []
   },
   "source": [
    "# Load train, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da507b18-110e-462a-97c3-3c0364ef61a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:09:23.969974Z",
     "iopub.status.busy": "2024-04-14T07:09:23.969736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_records = prepare_dataset('full_train_zeros.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e22a0-0069-4a78-8ca1-71fd9383c873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_records = prepare_dataset('test_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d0d16-e61e-4058-95c3-a7d359812d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PersistDataset(\n",
    "    data=train_records,\n",
    ")\n",
    "\n",
    "test_dataset = PersistDataset(\n",
    "    data=test_records,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd3a84-b31b-4ee8-be48-29cde1d88fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e641cb-93bf-4a78-83f9-cdaf9800842b",
   "metadata": {},
   "source": [
    "# Coles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2aada8-94e9-458d-a95c-d9f3ee507e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PersistDataset(\n",
    "    data=train_records,\n",
    ")\n",
    "\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            'quarter': {'in': 4, 'out': 8},\n",
    "            'year': {'in': 23, 'out': 31}\n",
    "        },\n",
    "        numeric_values={\n",
    "            'npo_sum': 'log',\n",
    "        },\n",
    "        embeddings_noise=0.001,\n",
    "    ),\n",
    "    hidden_size=32,\n",
    "    type='gru',\n",
    ")\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
    ")\n",
    "\n",
    "train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        train_dataset,\n",
    "        splitter=SampleSlices(\n",
    "            split_count=5,\n",
    "            cnt_min=25,\n",
    "            cnt_max=200,\n",
    "        ),\n",
    "    ),\n",
    "    train_num_workers=4,\n",
    "    train_batch_size=256,\n",
    ")\n",
    "\n",
    "trainer = ptl.Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=3,\n",
    ")\n",
    "\n",
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(model, train_dl)\n",
    "print(trainer.logged_metrics)\n",
    "\n",
    "torch.save(seq_encoder.state_dict(), \"coles-emb_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c4871-f400-4dad-a084-b553fa7fb375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def emb_inference(records, path_encoder):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    seq_encoder = RnnSeqEncoder(\n",
    "        trx_encoder=TrxEncoder(\n",
    "                embeddings={\n",
    "                    'quarter': {'in': 4, 'out': 8},\n",
    "                    'year': {'in': 23, 'out': 31}\n",
    "                },\n",
    "                numeric_values={\n",
    "                    'npo_sum': 'log',\n",
    "                },\n",
    "                embeddings_noise=0.001,\n",
    "            ),\n",
    "            hidden_size=32,\n",
    "            type='gru',\n",
    "    )\n",
    "\n",
    "    seq_encoder.load_state_dict(torch.load(path_encoder, map_location=device))\n",
    "    model = CoLESModule(seq_encoder)\n",
    "    model.eval()\n",
    "    trainer = ptl.Trainer(gpus=1 if torch.cuda.is_available() else 0)\n",
    "    train_dl = inference_data_loader(records, num_workers=0, batch_size=256)\n",
    "    train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
    "    \n",
    "    return train_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301321c-f6be-4983-b912-0d208e68c66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:30:53.013008Z",
     "iopub.status.busy": "2024-04-14T06:30:53.012730Z",
     "iopub.status.idle": "2024-04-14T06:32:52.021075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 28 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: : 5it [00:00, 69.21it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:173: UserWarning: Lightning couldn't infer the indices fetched for your dataloader.\n",
      "  warning_cache.warn(\"Lightning couldn't infer the indices fetched for your dataloader.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: : 7011it [01:58, 59.13it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeds = emb_inference(train_records, 'coles-emb_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07e3a871-18cb-4126-b7d6-956a0b50a2a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T00:43:16.185391Z",
     "iopub.status.busy": "2024-04-14T00:43:16.185022Z",
     "iopub.status.idle": "2024-04-14T00:43:43.738661Z",
     "shell.execute_reply": "2024-04-14T00:43:43.737983Z",
     "shell.execute_reply.started": "2024-04-14T00:43:16.185367Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: : 178it [00:27,  6.48it/s]\n"
     ]
    }
   ],
   "source": [
    "test_embeds = emb_inference(test_records, 'coles-emb_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbaad940-5013-4504-9728-52d1d491b5c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:35:50.768208Z",
     "iopub.status.busy": "2024-04-14T06:35:50.767801Z",
     "iopub.status.idle": "2024-04-14T06:35:50.792206Z",
     "shell.execute_reply": "2024-04-14T06:35:50.791655Z",
     "shell.execute_reply.started": "2024-04-14T06:35:50.768188Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def id_to_emb(records, emb, test=False):\n",
    "    assert len(records) == len(emb), f'len of records must be equal to len of emb: {records.shape[0]}, {emb.shape[0]} '\n",
    "    print(len(records))\n",
    "    \n",
    "    emb_dim = emb.shape[-1]\n",
    "    res_dict = {\n",
    "        'npo_account_id': [],\n",
    "        'year': [],\n",
    "        'quarter': [],\n",
    "        'target_churn': []\n",
    "    }\n",
    "    res_dict.update({\n",
    "        f'emb_{i}': [] for i in range(emb_dim)\n",
    "    })\n",
    "    \n",
    "    if not test:\n",
    "        res_dict['target_churn'] = []\n",
    "    for i in tqdm(range(len(records))):\n",
    "        #print(records[i])\n",
    "        #Int32\n",
    "        res_dict['npo_account_id'].append(records[i]['npo_account_id'])\n",
    "        res_dict['year'].append(records[i]['tyear']  + 1999)\n",
    "        res_dict['quarter'].append(records[i]['target_quarter'] + 1)\n",
    "        if not test:\n",
    "            res_dict['target_churn'].append(records[i]['target_churn'])\n",
    "        for key in res_dict.keys():\n",
    "            if 'emb_' in key:\n",
    "                idx = int(key.split('_')[-1])\n",
    "                res_dict[key].append(emb[i][idx])\n",
    "        \n",
    "    return pl.DataFrame(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc51f6-45f4-42d4-a6c1-5e1c9bca413f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T06:35:52.143419Z",
     "iopub.status.busy": "2024-04-14T06:35:52.143021Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1794648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1389074/1794648 [15:01<03:23, 1993.31it/s] "
     ]
    },
    {
     "ename": "\u001b[0;31mKernelOutOfMemory\u001b[0m",
     "evalue": "Kernel ran out of memory and has been restarted. If the restart fails, restart the kernel from the Kernel menu.\nIf the error persists, try choosing a different configuration or optimizing your code.",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "emb_train_features = id_to_emb(train_records, train_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b6b35-6da6-4771-9f78-3dd1bff63c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_test_features = id_to_emb(test_records, train_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9208c6d-372a-48bb-93b1-e76994b30552",
   "metadata": {},
   "source": [
    "# Catboost emb only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f462875-e43d-4daf-9467-75fa04cc985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=1000,\n",
    "                            learning_rate=0.01,\n",
    "                            depth=6,\n",
    "                            verbose=300,\n",
    "                            random_seed=42,\n",
    "                            eval_metric='F1',\n",
    "                            task_type=\"GPU\",\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed29d2-3156-4816-885e-e31b15b6dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(emb_train_features.drop('target_curn'), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8aef8-6f72-47fb-a1a0-d99be81a560a",
   "metadata": {},
   "source": [
    "## SeqToTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8182ea6-beca-449d-9d15-a577770bd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset = PersistDataset(\n",
    "    data=train_records,\n",
    ")\n",
    "\n",
    "valid_dataset = PersistDataset(\n",
    "    data=train_records,\n",
    ")\n",
    "\n",
    "test_dataset = PersistDataset(\n",
    "    data=train_records,\n",
    ")\n",
    "\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(\n",
    "            embeddings={\n",
    "                'quarter': {'in': 4, 'out': 8},\n",
    "                'year': {'in': 19, 'out': 31}\n",
    "            },\n",
    "            numeric_values={\n",
    "                'npo_sum': 'log',\n",
    "            },\n",
    "            embeddings_noise=0.001,\n",
    "        ),\n",
    "        hidden_size=32,\n",
    "        type='gru',\n",
    ")\n",
    "\n",
    "sup_module = SequenceToTarget(\n",
    "        seq_encoder=seq_encoder,\n",
    "        head=Head(input_size=seq_encoder.embedding_size, objective='classification', num_classes=2),\n",
    "        loss=torch.nn.NLLLoss(),\n",
    "        metric_list=torchmetrics.F1Score(num_classes=2, average='macro'),\n",
    "        optimizer_partial=partial(torch.optim.Adam),\n",
    "        lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=4, gamma=0.5),\n",
    ")\n",
    "\n",
    "sup_data = PtlsDataModule(\n",
    "    train_data=SeqToTargetDataset(train_dataset, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    valid_data=SeqToTargetDataset(valid_dataset, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    test_data=SeqToTargetDataset(test_dataset, target_col_name='target_bin', target_dtype=torch.long),\n",
    "    train_batch_size=512,\n",
    "    valid_batch_size=128,\n",
    "    train_num_workers=4,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(sup_module, sup_data)\n",
    "\n",
    "trainer.test(ckpt_path='best', dataloaders=sup_data.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735dc7e4-ac94-4509-86bc-2273a2ea2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.frames.inference_module import InferenceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023807c-4398-442e-b986-cd8d73f90692",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dl = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    collate_fn=collate_feature_dict,\n",
    "    shuffle=False,\n",
    "    batch_size=1000,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69762285-c0b5-4f25-8c1b-122b5211d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_module = InferenceModule(\n",
    "    torch.nn.Sequential(\n",
    "        sup_module,\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dae5e0-841b-4d3e-adb8-ba5951e36709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = trainer.predict(inf_module, inference_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c49119-b5cf-4e8c-bc5d-64915913fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.concat(df_predict, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
